{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43b6f0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\anaconda3\\envs\\emova\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from src.models import AffectModel, masked_mse_loss\n",
    "from src.data import setup_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254a25ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "TRAIN_PATH = \"data/TRAIN_RELEASE_3SEP2025/train_subtask1.csv\"\n",
    "TOKENIZER_PATH = \"bert-base-uncased\"\n",
    "\n",
    "MODEL_CONFIG = {\n",
    "    # Encoder\n",
    "    'model_path': 'bert-base-uncased',\n",
    "    'n_groups': 4,\n",
    "    'grouped_mode': 'attention',\n",
    "    'pooling': 'mean',\n",
    "    'freeze_backbone': True,\n",
    "    'conv_kernel_size': 3,\n",
    "    # LSTM\n",
    "    'lstm_hidden': 256,\n",
    "    'lstm_layers': 2,\n",
    "    'bidirectional': True,\n",
    "    # Head\n",
    "    'constrain_arousal': True,\n",
    "    # Shared\n",
    "    'dropout': 0.3,\n",
    "}\n",
    "\n",
    "DATA_CONFIG = {\n",
    "    'csv_path': TRAIN_PATH,\n",
    "    'tokenizer_path': TOKENIZER_PATH,\n",
    "    'max_text_length': 512,\n",
    "    'batch_size': 4,\n",
    "    'shuffle': True,\n",
    "    'num_workers': 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b769c3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 137 users\n",
      "Model parameters: 119,850,246\n",
      "Trainable parameters: 10,368,006\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "train_loader, train_dataset = setup_dataloader(**DATA_CONFIG)\n",
    "model = AffectModel(**MODEL_CONFIG)\n",
    "\n",
    "print(f\"Dataset size: {len(train_dataset)} users\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5075281c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([4, 8, 512])\n",
      "Predictions: torch.Size([4, 8, 2])\n",
      "Targets: torch.Size([4, 8, 2])\n",
      "Loss: 1.3923\n"
     ]
    }
   ],
   "source": [
    "# Test forward pass\n",
    "for batch in train_loader:\n",
    "    predictions = model(\n",
    "        input_ids=batch['input_ids'],\n",
    "        attention_mask=batch['attention_mask'],\n",
    "        seq_lengths=batch['seq_lengths'],\n",
    "        seq_mask=batch['seq_attention_mask']\n",
    "    )\n",
    "    \n",
    "    targets = torch.stack([batch['valences'], batch['arousals']], dim=-1)\n",
    "    mask = batch['seq_attention_mask'].bool()\n",
    "    loss = masked_mse_loss(predictions, targets, mask)\n",
    "    \n",
    "    print(f\"Input shape: {batch['input_ids'].shape}\")\n",
    "    print(f\"Predictions: {predictions.shape}\")\n",
    "    print(f\"Targets: {targets.shape}\")\n",
    "    print(f\"Loss: {loss.item():.4f}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e42e0ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence range: [-2.00, 2.00]\n",
      "Arousal range: [0.00, 2.00]\n",
      "Prediction range: [-0.08, 1.02]\n",
      "Valid timesteps: 22 / 32 (68.8%)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Valence range: [{batch['valences'].min():.2f}, {batch['valences'].max():.2f}]\")\n",
    "print(f\"Arousal range: [{batch['arousals'].min():.2f}, {batch['arousals'].max():.2f}]\")\n",
    "print(f\"Prediction range: [{predictions.min():.2f}, {predictions.max():.2f}]\")\n",
    "print(f\"Valid timesteps: {mask.sum()} / {mask.numel()} ({100*mask.sum()/mask.numel():.1f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emova",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
